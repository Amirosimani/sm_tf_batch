{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow, TensorFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-us-east-1-367158743199\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "# sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "prefix = 'frontier'\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "X, y = datasets.make_moons(1000, noise=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/X_train.npy', X_train)\n",
    "np.save('./data/y_train.npy', y_train)\n",
    "\n",
    "np.save('./data/X_val.npy', X_test)\n",
    "np.save('./data/y_val.npy', y_test)\n",
    "\n",
    "\n",
    "training_data_uri = f\"s3://{bucket}/{prefix}/input\"\n",
    "\n",
    "s3.meta.client.upload_file('./data/X_train.npy', bucket, f'{prefix}/input/X_train.npy')\n",
    "s3.meta.client.upload_file('./data/y_train.npy', bucket, f'{prefix}/input/y_train.npy')\n",
    "s3.meta.client.upload_file('./data/X_val.npy', bucket, f'{prefix}/input/X_val.npy')\n",
    "s3.meta.client.upload_file('./data/y_val.npy', bucket, f'{prefix}/input/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Generate a simple model\"\"\"\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=[x_train.shape[1]]),\n",
    "            tf.keras.layers.Dense(2, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(model.summary)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train)\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    return model\n",
    "\n",
    "def _load_training_data(base_dir):\n",
    "    \"\"\"Load training data\"\"\"\n",
    "    x_train = np.load(os.path.join(base_dir, \"X_train.npy\"))\n",
    "    y_train = np.load(os.path.join(base_dir, \"y_train.npy\"))\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def _load_validation_data(base_dir):\n",
    "    \"\"\"Load testing data\"\"\"\n",
    "    x_test = np.load(os.path.join(base_dir, \"X_val.npy\"))\n",
    "    y_test = np.load(os.path.join(base_dir, \"y_val.npy\"))\n",
    "    return x_test, y_test\n",
    "\n",
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument(\"--model_dir\", type=str)\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args, unknown = _parse_args()\n",
    "    \n",
    "    train_data, train_labels = _load_training_data(args.train)\n",
    "    eval_data, eval_labels = _load_validation_data(args.train)\n",
    "\n",
    "    clf = model(train_data, train_labels, eval_data, eval_labels)\n",
    "    clf.save(os.path.join(args.sm_model_dir, \"000000001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\n",
      "2021-06-29 20:30:33.913186: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2021-06-29 20:30:33.913309: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2021-06-29 20:30:33.945391: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2021-06-29 20:30:35.255764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-29 20:30:35.263627: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499985000 Hz\n",
      "2021-06-29 20:30:35.263850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557db652f290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-29 20:30:35.263883: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-29 20:30:35.264098: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "[2021-06-29 20:30:35.470 tensorflow-2-3-cpu-py-ml-t3-medium-dbca98283d57d615662c4efa28c8:628 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-06-29 20:30:35.608 tensorflow-2-3-cpu-py-ml-t3-medium-dbca98283d57d615662c4efa28c8:628 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f1a5d48f810>>\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.2688\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.3400\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2021-06-29 20:30:36.580436: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model/000000001/assets\n",
      "INFO:tensorflow:Assets written to: ./model/000000001/assets\n"
     ]
    }
   ],
   "source": [
    "# # test locally\n",
    "# !mkdir model\n",
    "# ! python src/train.py  --sm-model-dir ./model/ \\\n",
    "#                    --train ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 20:30:37 Starting - Starting the training job...\n",
      "2021-06-29 20:31:01 Starting - Launching requested ML instancesProfilerReport-1624998637: InProgress\n",
      "......\n",
      "2021-06-29 20:32:01 Starting - Preparing the instances for training.........\n",
      "2021-06-29 20:33:26 Downloading - Downloading input data...\n",
      "2021-06-29 20:34:01 Training - Downloading the training image.........\n",
      "2021-06-29 20:35:32 Uploading - Uploading generated training model\u001b[34m2021-06-29 20:35:22,011 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-06-29 20:35:22,445 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-06-29-20-30-37-585\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-367158743199/tensorflow-training-2021-06-29-20-30-37-585/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-367158743199/tensorflow-training-2021-06-29-20-30-37-585/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-06-29-20-30-37-585\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-367158743199/tensorflow-training-2021-06-29-20-30-37-585/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py --model_dir s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m<bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fc91f83a518>>\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:27.420 ip-10-2-213-127.ec2.internal:27 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:27.421 ip-10-2-213-127.ec2.internal:27 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:27.421 ip-10-2-213-127.ec2.internal:27 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mTrain on 800 samples\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:27.478 ip-10-2-213-127.ec2.internal:27 INFO keras.py:68] Executing in TF2.x eager mode.TF 2.x eager doesn't provide gradient and optimizer variable values.SageMaker Debugger will not be saving gradients and optimizer variables in this case\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:27.488 ip-10-2-213-127.ec2.internal:27 INFO hook.py:364] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\u001b[34m#015 32/800 [>.............................] - ETA: 23s - loss: 0.8125 - accuracy: 0.1250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015736/800 [==========================>...] - ETA: 0s - loss: 0.7648 - accuracy: 0.1753 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015800/800 [==============================] - 1s 1ms/sample - loss: 0.7654 - accuracy: 0.1675\u001b[0m\n",
      "\u001b[34m#015 32/200 [===>..........................] - ETA: 0s - loss: 0.7311 - accuracy: 0.2500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015200/200 [==============================] - 0s 545us/sample - loss: 0.7494 - accuracy: 0.2400\u001b[0m\n",
      "\u001b[34m2021-06-29 20:35:28.861296: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/000000001/assets\u001b[0m\n",
      "\u001b[34m[2021-06-29 20:35:29.073 ip-10-2-213-127.ec2.internal:27 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2021-06-29 20:35:29,571 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-29 20:36:02 Completed - Training job completed\n",
      "ProfilerReport-1624998637: NoIssuesFound\n",
      "Training seconds: 135\n",
      "Billable seconds: 135\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point=\"./src/train.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    framework_version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    ")\n",
    "\n",
    "# estimator.fit({\"train\": train_input, \"validation\": validation_input})\n",
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-training-2021-06-29-20-30-37-585'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact persisted at s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Get information about the best training job\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=estimator._current_job_name)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data as jsonlines\n",
    "test_data = []\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    data_row = {'id': int(i),\n",
    "               'data': [float(x) for x in X[i].tolist()]\n",
    "               }\n",
    "    test_data.append(data_row)\n",
    "      \n",
    "with open('./data/test_data.jsonl', 'w') as f:\n",
    "    for entry in test_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "        \n",
    "s3.meta.client.upload_file('./data/test_data.jsonl', bucket, f'{prefix}/X_test.jsonl')\n",
    "test_s3_uri = f\"s3://{bucket}/{prefix}/X_test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 199, 'data': [0.1269050880890254, 0.4463074970347955]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/inference.py\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def handler(data, context):\n",
    "    \"\"\"Handle request.\n",
    "    Args:\n",
    "        data (obj): the request data\n",
    "        context (Context): an object containing request and configuration details\n",
    "    Returns:\n",
    "        (bytes, string): data to return to client, (optional) response content type\n",
    "    \"\"\"\n",
    "    processed_input = _process_input(data, context)\n",
    "    response = requests.post(context.rest_uri, data=processed_input)\n",
    "    return _process_output(response, context)\n",
    "\n",
    "\n",
    "def _process_input(data, context):\n",
    "    if context.request_content_type == 'application/json':\n",
    "        # pass through json (assumes it's correctly formed)\n",
    "        d = data.read().decode('utf-8')\n",
    "        print(d)\n",
    "        return d['feature_data'] if len(d) else ''\n",
    "\n",
    "    raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(\n",
    "        context.request_content_type or \"unknown\"))\n",
    "\n",
    "\n",
    "def _process_output(data, context):\n",
    "    if data.status_code != 200:\n",
    "        raise ValueError(data.content.decode('utf-8'))\n",
    "\n",
    "    response_content_type = context.accept_header\n",
    "    prediction = data.content\n",
    "    return prediction, response_content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact = \"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-17-35-28-662/output/model.tar.gz\"\n",
    "# create a TF model\n",
    "model = TensorFlowModel(model_data=artifact,\n",
    "#                         entry_point='./src/inference.py',\n",
    "                        role=role,\n",
    "                        framework_version=\"2.1.0\"                        \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-367158743199/frontier/transform/\n",
      "............................\u001b[34mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[34mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[35mINFO:__main__:starting services\u001b[0m\n",
      "\u001b[35mINFO:__main__:using default model name: model\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[34mmodel_config_list: {\n",
      "  config: {\n",
      "    name: \"model\",\n",
      "    base_path: \"/opt/ml/model\",\n",
      "    model_platform: \"tensorflow\"\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[34mload_module modules/ngx_http_js_module.so;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr error;\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving model config: \u001b[0m\n",
      "\u001b[35mmodel_config_list: {\n",
      "  config: {\n",
      "    name: \"model\",\n",
      "    base_path: \"/opt/ml/model\",\n",
      "    model_platform: \"tensorflow\"\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx config: \u001b[0m\n",
      "\u001b[35mload_module modules/ngx_http_js_module.so;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr error;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_include tensorflow-serving.js;\n",
      "\n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "\n",
      "    set $tfs_version 2.1;\n",
      "    set $default_tfs_model model;\n",
      "\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "\n",
      "    location /ping {\n",
      "        js_content ping_without_model;\n",
      "    }\n",
      "\n",
      "    location /invocations {\n",
      "        js_content invocations;\n",
      "    }\n",
      "\n",
      "    location ~ ^/models/(.*)/invoke {\n",
      "        js_content invocations;\n",
      "    }\n",
      "\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[34mTensorFlow ModelServer: 2.1.0-rc1+dev.sha.075ffcf\u001b[0m\n",
      "\u001b[34mTensorFlow Library: 2.1.0\u001b[0m\n",
      "\u001b[34mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \u001b[0m\n",
      "\u001b[34mINFO:__main__:started tensorflow serving (pid: 11)\u001b[0m\n",
      "\u001b[34mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/json;\n",
      "  access_log /dev/stdout combined;\n",
      "  js_include tensorflow-serving.js;\n",
      "\n",
      "  upstream tfs_upstream {\n",
      "    server localhost:10001;\n",
      "  }\n",
      "\n",
      "  upstream gunicorn_upstream {\n",
      "    server unix:/tmp/gunicorn.sock fail_timeout=1;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    client_body_buffer_size 100m;\n",
      "    subrequest_output_buffer_size 100m;\n",
      "\n",
      "    set $tfs_version 2.1;\n",
      "    set $default_tfs_model model;\n",
      "\n",
      "    location /tfs {\n",
      "        rewrite ^/tfs/(.*) /$1  break;\n",
      "        proxy_redirect off;\n",
      "        proxy_pass_request_headers off;\n",
      "        proxy_set_header Content-Type 'application/json';\n",
      "        proxy_set_header Accept 'application/json';\n",
      "        proxy_pass http://tfs_upstream;\n",
      "    }\n",
      "\n",
      "    location /ping {\n",
      "        js_content ping_without_model;\n",
      "    }\n",
      "\n",
      "    location /invocations {\n",
      "        js_content invocations;\n",
      "    }\n",
      "\n",
      "    location ~ ^/models/(.*)/invoke {\n",
      "        js_content invocations;\n",
      "    }\n",
      "\n",
      "    location /models {\n",
      "        proxy_pass http://gunicorn_upstream/models;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "        return 404 '{\"error\": \"Not Found\"}';\n",
      "    }\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow version info:\u001b[0m\n",
      "\u001b[35mTensorFlow ModelServer: 2.1.0-rc1+dev.sha.075ffcf\u001b[0m\n",
      "\u001b[35mTensorFlow Library: 2.1.0\u001b[0m\n",
      "\u001b[35mINFO:__main__:tensorflow serving command: tensorflow_model_server --port=10000 --rest_api_port=10001 --model_config_file=/sagemaker/model-config.cfg --max_num_load_retries=0 \u001b[0m\n",
      "\u001b[35mINFO:__main__:started tensorflow serving (pid: 11)\u001b[0m\n",
      "\u001b[35mINFO:__main__:nginx version info:\u001b[0m\n",
      "\u001b[34mnginx version: nginx/1.18.0\u001b[0m\n",
      "\u001b[34mbuilt by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \u001b[0m\n",
      "\u001b[34mbuilt with OpenSSL 1.1.1  11 Sep 2018\u001b[0m\n",
      "\u001b[34mTLS SNI support enabled\u001b[0m\n",
      "\u001b[34mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.18.0/debian/debuild-base/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[34mINFO:__main__:started nginx (pid: 13)\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.630502: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.630554: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.731022: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.731077: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.731093: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.731107: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.731145: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.733557: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.733597: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.734862: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.778785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.834801: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[35mnginx version: nginx/1.18.0\u001b[0m\n",
      "\u001b[35mbuilt by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) \u001b[0m\n",
      "\u001b[35mbuilt with OpenSSL 1.1.1  11 Sep 2018\u001b[0m\n",
      "\u001b[35mTLS SNI support enabled\u001b[0m\n",
      "\u001b[35mconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -fdebug-prefix-map=/data/builder/debuild/nginx-1.18.0/debian/debuild-base/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'\u001b[0m\n",
      "\u001b[35mINFO:__main__:started nginx (pid: 13)\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.630502: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.630554: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: model\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.731022: I tensorflow_serving/util/retrier.cc:46] Retrying of Reserving resources for servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.731077: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.731093: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.731107: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.731145: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.733557: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.733597: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.734862: I external/org_tensorflow/tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.778785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.834801: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /opt/ml/model/000000001\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.840964: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 109821 microseconds.\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.841422: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/000000001/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.841791: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.841812: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.844312: I tensorflow_serving/model_servers/server.cc:362] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[34m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[34m2021-06-29 20:40:50.845441: I tensorflow_serving/model_servers/server.cc:382] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[34m[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.840964: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 109821 microseconds.\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.841422: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /opt/ml/model/000000001/assets.extra/tf_serving_warmup_requests\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.841791: I tensorflow_serving/util/retrier.cc:46] Retrying of Loading servable: {name: model version: 1} exhausted max_num_retries: 0\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.841812: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model version: 1}\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.844312: I tensorflow_serving/model_servers/server.cc:362] Running gRPC ModelServer at 0.0.0.0:10000 ...\u001b[0m\n",
      "\u001b[35m[warn] getaddrinfo: address family for nodename not supported\u001b[0m\n",
      "\u001b[35m2021-06-29 20:40:50.845441: I tensorflow_serving/model_servers/server.cc:382] Exporting HTTP/REST API at:localhost:10001 ...\u001b[0m\n",
      "\u001b[35m[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"GET /execution-parameters HTTP/1.1\" 404 22 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"POST /invocations HTTP/1.1\" 200 3007 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Jun/2021:20:40:55 +0000] \"POST /invocations HTTP/1.1\" 200 3007 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-06-29T20:40:55.389:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/transform/'\n",
    "print(batch_output)\n",
    "\n",
    "tf_transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    accept = 'application/jsonlines',\n",
    "    output_path= batch_output,\n",
    "    assemble_with = 'Line',\n",
    "\n",
    ")\n",
    "\n",
    "tf_transformer.transform(test_s3_uri, \n",
    "                         content_type='application/jsonlines',\n",
    "                         split_type='Line',\n",
    "                         input_filter = \"$.data\",\n",
    "#                          output_filter=\"$['id','SageMakerOutput']\",\n",
    "#                         join_source = \"Input\",\n",
    ")\n",
    "\n",
    "\n",
    "# I am checking with service team to understand why joining sources with jsonlines is returning error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./output’: File exists\n",
      "download: s3://sagemaker-us-east-1-367158743199/frontier/transform/X_test.jsonl.out to output/X_test.jsonl.out\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./output\n",
    "!aws s3 cp {batch_output} ./output --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/X_test.jsonl.out') as f:\n",
    "    for line in f:\n",
    "        j_content = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.595570147],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.514561117],\n",
       " [0.499498218],\n",
       " [0.536596298],\n",
       " [0.524701118],\n",
       " [0.497284353],\n",
       " [0.511146247],\n",
       " [0.497284353],\n",
       " [0.607224226],\n",
       " [0.616298795],\n",
       " [0.5916394],\n",
       " [0.630199194],\n",
       " [0.497284353],\n",
       " [0.554815233],\n",
       " [0.534981251],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.573644102],\n",
       " [0.604129851],\n",
       " [0.54785192],\n",
       " [0.500333428],\n",
       " [0.599979818],\n",
       " [0.497284353],\n",
       " [0.589829922],\n",
       " [0.497284353],\n",
       " [0.575754106],\n",
       " [0.526062548],\n",
       " [0.510247886],\n",
       " [0.527407765],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.507006884],\n",
       " [0.513528645],\n",
       " [0.590680182],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.610685349],\n",
       " [0.497284353],\n",
       " [0.626481473],\n",
       " [0.603338182],\n",
       " [0.590058684],\n",
       " [0.516494036],\n",
       " [0.497284353],\n",
       " [0.593872845],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.502238452],\n",
       " [0.505226135],\n",
       " [0.497284353],\n",
       " [0.519869864],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.552017391],\n",
       " [0.610081553],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.5190714],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.542136967],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.593130231],\n",
       " [0.555229306],\n",
       " [0.497284353],\n",
       " [0.595694423],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.643279195],\n",
       " [0.572392046],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.649275661],\n",
       " [0.562301874],\n",
       " [0.631231546],\n",
       " [0.497284353],\n",
       " [0.623543918],\n",
       " [0.626129746],\n",
       " [0.497284353],\n",
       " [0.626789927],\n",
       " [0.557022274],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.568314612],\n",
       " [0.577327609],\n",
       " [0.497284353],\n",
       " [0.545320153],\n",
       " [0.585570514],\n",
       " [0.497284353],\n",
       " [0.599005461],\n",
       " [0.497284353],\n",
       " [0.623926938],\n",
       " [0.497284353],\n",
       " [0.538732171],\n",
       " [0.500196576],\n",
       " [0.506650925],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.592885613],\n",
       " [0.623488486],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.617970884],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.51346159],\n",
       " [0.577691138],\n",
       " [0.551350772],\n",
       " [0.536166906],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.586739242],\n",
       " [0.497284353],\n",
       " [0.607003808],\n",
       " [0.497284353],\n",
       " [0.516796],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.542527318],\n",
       " [0.497284353],\n",
       " [0.497664571],\n",
       " [0.497284353],\n",
       " [0.556253076],\n",
       " [0.497284353],\n",
       " [0.5831936],\n",
       " [0.497284353],\n",
       " [0.605948448],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.632806301],\n",
       " [0.497284353],\n",
       " [0.539594889],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.616889715],\n",
       " [0.535050154],\n",
       " [0.60115993],\n",
       " [0.531527281],\n",
       " [0.519856334],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.630774319],\n",
       " [0.573185682],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.58506304],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.528995812],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.613321364],\n",
       " [0.50289923],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.497284353],\n",
       " [0.63781172],\n",
       " [0.617966413],\n",
       " [0.617661536],\n",
       " [0.497284353],\n",
       " [0.585721374],\n",
       " [0.497284353],\n",
       " [0.520909727],\n",
       " [0.59618181],\n",
       " [0.626105845],\n",
       " [0.607049584],\n",
       " [0.504898727],\n",
       " [0.497284353],\n",
       " [0.57395643],\n",
       " [0.497284353],\n",
       " [0.57892549],\n",
       " [0.497284353],\n",
       " [0.515931487]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_content['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
