{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow, TensorFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "# sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "prefix = 'frontier'\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "X, y = datasets.make_moons(1000, noise=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/X_train.npy', X_train)\n",
    "np.save('./data/y_train.npy', y_train)\n",
    "\n",
    "np.save('./data/X_val.npy', X_test)\n",
    "np.save('./data/y_val.npy', y_test)\n",
    "\n",
    "\n",
    "training_data_uri = f\"s3://{bucket}/{prefix}/input\"\n",
    "\n",
    "s3.meta.client.upload_file('./data/X_train.npy', bucket, f'{prefix}/input/X_train.npy')\n",
    "s3.meta.client.upload_file('./data/y_train.npy', bucket, f'{prefix}/input/y_train.npy')\n",
    "s3.meta.client.upload_file('./data/X_val.npy', bucket, f'{prefix}/input/X_val.npy')\n",
    "s3.meta.client.upload_file('./data/y_val.npy', bucket, f'{prefix}/input/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src/train.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Generate a simple model\"\"\"\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=[x_train.shape[1]]),\n",
    "            tf.keras.layers.Dense(2, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(model.summary)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train)\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    return model\n",
    "\n",
    "def _load_training_data(base_dir):\n",
    "    \"\"\"Load training data\"\"\"\n",
    "    x_train = np.load(os.path.join(base_dir, \"X_train.npy\"))\n",
    "    y_train = np.load(os.path.join(base_dir, \"y_train.npy\"))\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def _load_validation_data(base_dir):\n",
    "    \"\"\"Load testing data\"\"\"\n",
    "    x_test = np.load(os.path.join(base_dir, \"X_val.npy\"))\n",
    "    y_test = np.load(os.path.join(base_dir, \"y_val.npy\"))\n",
    "    return x_test, y_test\n",
    "\n",
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument(\"--model_dir\", type=str)\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args, unknown = _parse_args()\n",
    "    \n",
    "    train_data, train_labels = _load_training_data(args.train)\n",
    "    eval_data, eval_labels = _load_validation_data(args.train)\n",
    "\n",
    "    clf = model(train_data, train_labels, eval_data, eval_labels)\n",
    "    clf.save(os.path.join(args.sm_model_dir, \"000000001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test locally\n",
    "# !mkdir model\n",
    "# ! python src/train.py  --sm-model-dir ./model/ \\\n",
    "#                    --train ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point=\"./src/train.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    framework_version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    ")\n",
    "\n",
    "# estimator.fit({\"train\": train_input, \"validation\": validation_input})\n",
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Get information about the best training job\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=estimator._current_job_name)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data as jsonlines\n",
    "test_data = []\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    data_row = {'id': int(i),\n",
    "               'data': [float(x) for x in X[i].tolist()]\n",
    "               }\n",
    "    test_data.append(data_row)\n",
    "      \n",
    "with open('./data/test_data.jsonl', 'w') as f:\n",
    "    for entry in test_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "        \n",
    "s3.meta.client.upload_file('./data/test_data.jsonl', bucket, f'{prefix}/X_test.jsonl')\n",
    "test_s3_uri = f\"s3://{bucket}/{prefix}/X_test.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = \"s3://sagemaker-us-east-1-367158743199/frontier/output/tensorflow-training-2021-06-29-20-30-37-585/output/model.tar.gz\"\n",
    "model = TensorFlowModel(model_data=artifact,\n",
    "#                         entry_point='./src/inference.py',\n",
    "                        role=role,\n",
    "                        framework_version=\"2.1.0\"                        \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/transform/'\n",
    "print(batch_output)\n",
    "\n",
    "tf_transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    accept = 'application/jsonlines',\n",
    "    output_path= batch_output,\n",
    "#     assemble_with = 'Line'\n",
    ")\n",
    "\n",
    "tf_transformer.transform(test_s3_uri, \n",
    "                         content_type='application/jsonlines',\n",
    "                         split_type='Line',\n",
    "                         input_filter = \"$.data\",\n",
    "#                          output_filter=\"$['id','SageMakerOutput']\",\n",
    "#                         join_source = \"Input\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am checking with service team to confirm when native support for joining sources for TF and json lines input will be added...in the meantime, you can use the following work around.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./output\n",
    "!aws s3 cp {batch_output} ./output --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/X_test.jsonl.out') as f:\n",
    "    for line in f:\n",
    "        j_content = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    test_data[i]['prediction'] = j_content['predictions'][i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ./src/inference.py\n",
    "\n",
    "# import json\n",
    "# import requests\n",
    "\n",
    "# def handler(data, context):\n",
    "#     \"\"\"Handle request.\n",
    "#     Args:\n",
    "#         data (obj): the request data\n",
    "#         context (Context): an object containing request and configuration details\n",
    "#     Returns:\n",
    "#         (bytes, string): data to return to client, (optional) response content type\n",
    "#     \"\"\"\n",
    "#     processed_input = _process_input(data, context)\n",
    "#     response = requests.post(context.rest_uri, data=processed_input)\n",
    "#     print(response.content)\n",
    "#     return _process_output(response, context)\n",
    "\n",
    "\n",
    "# def _process_input(data, context):\n",
    "#     if context.request_content_type == 'application/jsonlines':\n",
    "#         # pass through json (assumes it's correctly formed)\n",
    "#         d = data.read().decode('utf-8')\n",
    "# #         print(type(d), len(d), \"*******\", \"\\n\", d)\n",
    "#         d = [json.loads(l)['data'] for l in d.splitlines()]\n",
    "#         d = '\\n'.join(str(i) for i in d)\n",
    "#         return d if len(d) else ''\n",
    "\n",
    "#     raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(\n",
    "#         context.request_content_type or \"unknown\"))\n",
    "\n",
    "\n",
    "# def _process_output(data, context):\n",
    "#     if data.status_code != 200:\n",
    "#         raise ValueError(data.content.decode('utf-8'))\n",
    "\n",
    "#     response_content_type = context.accept_header\n",
    "#     prediction = data.content\n",
    "#     return prediction, response_content_type\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
